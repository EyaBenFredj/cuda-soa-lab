pipeline {
    agent any
    
    environment {
        DOCKER_REGISTRY = '10.90.90.100:5000'
        IMAGE_NAME = "cuda-soa-lab"
        STUDENT_ID = "EyaBenFredj"
        STUDENT_PORT = "8000"
        DOCKER_IMAGE = "${DOCKER_REGISTRY}/${IMAGE_NAME}:${STUDENT_ID}"
    }

    stages {
        stage('Checkout Code') {
            steps {
                echo 'üì• Checking out code from GitHub...'
                git branch: 'main', url: 'https://github.com/EyaBenFredj/cuda-soa-lab.git'
                sh 'ls -la'
            }
        }

        stage('GPU Sanity Test') {
            steps {
                echo 'üîß Installing required dependencies for cuda_test...'
                sh '''
                    python3 -c "
                    try:
                        import numpy as np
                        print('‚úÖ NumPy installed successfully')
                        
                        # Create test matrices
                        matrix_a = np.random.rand(100, 100).astype(np.float32)
                        matrix_b = np.random.rand(100, 100).astype(np.float32)
                        np.savez('test_matrix_a.npz', matrix_a)
                        np.savez('test_matrix_b.npz', matrix_b)
                        print('‚úÖ Test matrices created successfully')
                    except Exception as e:
                        print(f'‚ùå Dependency test failed: {e}')
                        exit 1
                    "
                '''
                
                echo 'üéÆ Running CUDA sanity check...'
                sh '''
                    python3 -c "
                    try:
                        # Test basic imports
                        import fastapi, uvicorn, prometheus_client
                        print('‚úÖ FastAPI and monitoring dependencies OK')
                        
                        # Test CUDA availability
                        try:
                            from numba import cuda
                            if cuda.is_available():
                                print('‚úÖ CUDA is available via Numba')
                                print(f'Number of GPUs detected: {len(cuda.list_devices())}')
                                
                                # Test simple CUDA operation
                                @cuda.jit
                                def add_kernel(a, b, c):
                                    i = cuda.grid(1)
                                    if i < c.size:
                                        c[i] = a[i] + b[i]
                                
                                # Test small array addition
                                import numpy as np
                                n = 100
                                a = np.ones(n, dtype=np.float32)
                                b = np.ones(n, dtype=np.float32)
                                c = np.zeros(n, dtype=np.float32)
                                
                                # Copy to device and run kernel
                                d_a = cuda.to_device(a)
                                d_b = cuda.to_device(b)
                                d_c = cuda.to_device(c)
                                
                                add_kernel[32, 32](d_a, d_b, d_c)
                                cuda.synchronize()
                                
                                result = d_c.copy_to_host()
                                print('‚úÖ CUDA kernel execution successful')
                            else:
                                print('‚ö†Ô∏è CUDA not available (expected in CI environment)')
                        except ImportError:
                            print('‚ö†Ô∏è Numba/CUDA not available (expected in CI environment)')
                            
                    except Exception as e:
                        print(f'‚ùå CUDA sanity check failed: {e}')
                        exit 1
                    "
                '''
            }
        }

        stage('Build Docker Image') {
            steps {
                echo "üê≥ Building Docker image with GPU support..."
                script {
                    // Build the Docker image
                    docker.build("${DOCKER_IMAGE}")
                    
                    // Test the built image
                    sh """
                    docker run --rm ${DOCKER_IMAGE} python3 -c "
                    import sys
                    print('Python version:', sys.version)
                    try:
                        import fastapi, numpy, prometheus_client
                        print('‚úÖ All dependencies installed in container')
                    except ImportError as e:
                        print(f'‚ùå Missing dependency: {e}')
                        sys.exit(1)
                    "
                    """
                }
            }
        }

        stage('Test Container') {
            steps {
                echo "üß™ Testing Docker container functionality..."
                script {
                    // Test that the container starts and basic functionality works
                    sh """
                    docker run -d --name test-container -p 8080:8000 ${DOCKER_IMAGE}
                    sleep 10
                    
                    # Test health endpoint
                    curl -f http://localhost:8080/health || exit 1
                    echo '‚úÖ Health endpoint working'
                    
                    # Test GPU info endpoint
                    curl -f http://localhost:8080/gpu-info || echo '‚ö†Ô∏è GPU info not available (expected)'
                    
                    # Test metrics endpoint
                    curl -f http://localhost:8080/metrics | head -10
                    echo '‚úÖ Metrics endpoint working'
                    
                    # Cleanup test container
                    docker stop test-container
                    docker rm test-container
                    """
                }
            }
        }

        stage('Deploy Container') {
            steps {
                echo "üöÄ Deploying Docker container..."
                script {
                    // Push to registry
                    docker.withRegistry("http://${DOCKER_REGISTRY}") {
                        docker.image("${DOCKER_IMAGE}").push()
                    }
                    
                    // Deploy to production (this would typically involve orchestration)
                    sh """
                    echo "üì¶ Image pushed to registry: ${DOCKER_IMAGE}"
                    echo "üåê Service will be available at: http://10.90.90.100:${STUDENT_PORT}"
                    echo "üìä Monitoring: http://10.90.90.100:9090"
                    echo "üì∫ Dashboard: http://10.90.90.100:3000"
                    """
                    
                    // Optional: Actual deployment command would go here
                    // sh "kubectl set image deployment/gpu-service gpu-service=${DOCKER_IMAGE}"
                }
            }
        }

        stage('Integration Test') {
            steps {
                echo "üîç Running integration tests..."
                script {
                    sh """
                    # Wait for deployment to be ready
                    sleep 30
                    
                    # Test the deployed service
                    echo "Testing deployed service at http://10.90.90.100:${STUDENT_PORT}"
                    
                    # Test health endpoint
                    curl -f http://10.90.90.100:${STUDENT_PORT}/health && echo '‚úÖ Production health check PASSED'
                    
                    # Test GPU info
                    curl -f http://10.90.90.100:${STUDENT_PORT}/gpu-info && echo '‚úÖ GPU info endpoint working'
                    
                    # Test with actual matrix files
                    if [ -f "matrix1.npz" ] && [ -f "matrix2.npz" ]; then
                        curl -X POST http://10.90.90.100:${STUDENT_PORT}/add \
                             -F "file_a=@matrix1.npz" \
                             -F "file_b=@matrix2.npz" && echo '‚úÖ Matrix addition test PASSED'
                    else
                        echo '‚ö†Ô∏è Test matrices not found, skipping matrix addition test'
                    fi
                    """
                }
            }
        }
    }

    post {
        success {
            echo "üéâ Deployment completed successfully!"
            echo "Student: ${STUDENT_ID}"
            echo "Service URL: http://10.90.90.100:${STUDENT_PORT}"
            echo "GPU Info: http://10.90.90.100:${STUDENT_PORT}/gpu-info"
            echo "Metrics: http://10.90.90.100:9090"
            echo "Dashboard: http://10.90.90.100:3000"
        }
        failure {
            echo "üí• Deployment failed. Check logs for errors."
            sh """
            echo 'Last 50 lines of failed container logs:'
            docker logs test-container --tail 50 2>/dev/null || echo 'No test container found'
            """
        }
        always {
            echo "üßæ Pipeline finished."
            script {
                // Cleanup
                sh """
                docker rm -f test-container 2>/dev/null || true
                """
            }
        }
    }
}